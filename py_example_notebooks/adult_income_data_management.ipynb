{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Requisite Lbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os  # import operating system for dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import ensure_directory\n",
    "\n",
    "base_path = os.path.join(os.pardir)\n",
    "\n",
    "# Go up one level from 'notebooks' to parent directory,\n",
    "# then into the 'data' folder\n",
    "data_path = os.path.join(os.pardir, \"data\")\n",
    "data_output = os.path.join(os.pardir, \"data_output\")\n",
    "\n",
    "# create image paths\n",
    "image_path_png = os.path.join(base_path, \"images\", \"png_images\")\n",
    "image_path_svg = os.path.join(base_path, \"images\", \"svg_images\")\n",
    "\n",
    "# Use the function to ensure'data' directory exists\n",
    "ensure_directory(data_path)\n",
    "ensure_directory(data_output)\n",
    "ensure_directory(image_path_png)\n",
    "ensure_directory(image_path_svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCI ML Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# Combine X and y into entire df\n",
    "df = X.join(y, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import add_ids\n",
    "\n",
    "# Add a column of unique IDs with 9 digits and call it \"census_id\"\n",
    "df = add_ids(\n",
    "    df=df,\n",
    "    id_colname=\"census_id\",\n",
    "    num_digits=9,\n",
    "    seed=111,\n",
    "    set_as_index=True,\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.index.is_unique:\n",
    "    print(\"The index is unique.\")\n",
    "else:\n",
    "    print(\"The index is not unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Out the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_path, \"adult_income.csv\"))\n",
    "df.to_parquet(os.path.join(data_path, \"adult_income.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ages = [\n",
    "    0,\n",
    "    18,\n",
    "    30,\n",
    "    40,\n",
    "    50,\n",
    "    60,\n",
    "    70,\n",
    "    80,\n",
    "    90,\n",
    "    100,\n",
    "    float(\"inf\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ages = [\n",
    "    \"< 18\",\n",
    "    \"18-29\",\n",
    "    \"30-39\",\n",
    "    \"40-49\",\n",
    "    \"50-59\",\n",
    "    \"60-69\",\n",
    "    \"70-79\",\n",
    "    \"80-89\",\n",
    "    \"90-99\",\n",
    "    \"100 +\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"age\"],\n",
    "    bins=bin_ages,\n",
    "    labels=label_ages,\n",
    "    right=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate Income (Outcome) Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_merge(val):\n",
    "    if val == \"<=50K\" or val == \"<=50K.\":\n",
    "        return \"<=50K\"\n",
    "    else:\n",
    "        return \">50K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income\"] = df[\"income\"].apply(outcome_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import generate_table1\n",
    "\n",
    "table1 = generate_table1(\n",
    "    df=df,\n",
    "    value_counts=True,\n",
    "    max_categories=3,\n",
    "    export_markdown=True,\n",
    "    markdown_path=os.path.join(data_output, \"table1_summary.md\"),\n",
    ")\n",
    "\n",
    "table1 = table1.drop(columns=[\"Type\", \"Mode\"])\n",
    "table1.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import generate_table1\n",
    "\n",
    "# Get DataFrame and Markdown string\n",
    "df1 = generate_table1(\n",
    "    df,\n",
    "    value_counts=True,\n",
    "    decimal_places=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get markdown string (no tuple)\n",
    "md_only = generate_table1(\n",
    "    df,\n",
    "    export_markdown=True,\n",
    "    return_markdown_only=True,\n",
    "    combine=False,\n",
    "    include_types=\"continuous\",\n",
    "    markdown_path=os.path.join(data_output, \"table1_summary.md\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = generate_table1(\n",
    "    df,\n",
    "    export_markdown=True,\n",
    "    combine=False,\n",
    "    include_types=\"categorical\",\n",
    "    markdown_path=os.path.join(data_output, \"table1_summary.md\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Markdown to file\n",
    "generate_table1(\n",
    "    df,\n",
    "    value_counts=True,\n",
    "    export_markdown=True,\n",
    "    markdown_path=os.path.join(data_output, \"custom_prefix_table1_summary.md\"),\n",
    "    combine=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame and Markdown string\n",
    "df2 = generate_table1(\n",
    "    df,\n",
    "    value_counts=True,\n",
    "    include_types=\"categorical\",\n",
    "    # decimal_places=0,\n",
    "    combine=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3, df4 = generate_table1(\n",
    "    df,\n",
    "    value_counts=True,\n",
    "    include_types=\"both\",\n",
    "    max_categories=3,\n",
    "    export_markdown=True,\n",
    "    combine=False,\n",
    "    markdown_path=os.path.join(data_output, \"both_table1_summary.md\"),\n",
    ")\n",
    "\n",
    "df3 = df3.drop(columns=[\"Type\", \"Mode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1 with P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Equal-width bins\n",
    "\n",
    "df[\"fnlwgt_bin\"] = pd.cut(\n",
    "    df[\"fnlwgt\"], bins=5, labels=[f\"Bin {i}\" for i in range(1, 6)], include_lowest=True\n",
    ")\n",
    "\n",
    "# 2) Equal-frequency (quantile) bins\n",
    "df[\"fnlwgt_bin_quantile\"] = pd.qcut(\n",
    "    df[\"fnlwgt\"],\n",
    "    q=5,\n",
    "    labels=[f\"Q{i}\" for i in range(1, 6)],\n",
    "    duplicates=\"drop\",  # in case of ties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1_cat = df[[\"fnlwgt_bin\", \"age_group\", \"income\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_table_1_cat = generate_table1(\n",
    "    df_table1_cat,\n",
    "    value_counts=True,\n",
    "    include_types=\"categorical\",\n",
    "    export_markdown=True,\n",
    "    groupby_col=\"income\",\n",
    "    drop_columns=[\"Missing (n)\", \"Missing (%)\", \"income\", \"Type\", \"Mode\"],\n",
    "    drop_variables=\"income\",\n",
    "    markdown_path=os.path.join(data_output, \"p_val_table1_summary.md\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_table_1_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_value_table_1_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trailing Period Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import strip_trailing_period\n",
    "\n",
    "# Create a sample dataframe with trailing periods in some values\n",
    "data = {\n",
    "    \"values\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "}\n",
    "df_trail = pd.DataFrame(data)\n",
    "\n",
    "# Remove trailing periods from the 'values' column\n",
    "df_trail = strip_trailing_period(df=df_trail, column_name=\"values\")\n",
    "df_trail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardized Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import parse_date_with_rule\n",
    "\n",
    "# Sample date strings\n",
    "date_strings = [\"15/04/2021\", \"04/15/2021\", \"01/12/2020\", \"12/01/2020\"]\n",
    "\n",
    "# Standardize the date strings\n",
    "standardized_dates = [parse_date_with_rule(date) for date in date_strings]\n",
    "\n",
    "print(standardized_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DataFrame\n",
    "data = {\n",
    "    \"date_column\": [\n",
    "        \"31/12/2021\",\n",
    "        \"01/01/2022\",\n",
    "        \"12/31/2021\",\n",
    "        \"13/02/2022\",\n",
    "        \"07/04/2022\",\n",
    "    ],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"amount\": [100.0, 150.5, 200.75, 250.25, 300.0],\n",
    "}\n",
    "\n",
    "df_fake = pd.DataFrame(data)\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "df_fake[\"standardized_date\"] = df_fake[\"date_column\"].apply(parse_date_with_rule)\n",
    "\n",
    "print(df_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import dataframe_profiler\n",
    "\n",
    "dataframe_profiler(df=df, background_color=\"brown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Summary Tables for Variable Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import summarize_all_combinations\n",
    "\n",
    "# Define unique variables for the analysis\n",
    "unique_vars = [\n",
    "    \"age_group\",\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"occupation\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"income\",\n",
    "]\n",
    "\n",
    "# Generate summary tables for all combinations of the specified variables\n",
    "summary_tables, all_combinations = summarize_all_combinations(\n",
    "    df=df,\n",
    "    # data_path=data_output,\n",
    "    variables=unique_vars,\n",
    "    # data_name=\"census_summary_tables.xlsx\",\n",
    ")\n",
    "\n",
    "print(all_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrames to Excel with Customized Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import save_dataframes_to_excel\n",
    "\n",
    "# Example usage\n",
    "file_name = \"df_census.xlsx\"  # Name of the output Excel file\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "\n",
    "# filter DataFrame to Ages 18-40\n",
    "filtered_df = df[(df[\"age\"] > 18) & (df[\"age\"] < 40)]\n",
    "\n",
    "df_dict = {\n",
    "    \"original_df\": df,\n",
    "    \"ages_18_to_40\": filtered_df,\n",
    "}\n",
    "\n",
    "save_dataframes_to_excel(\n",
    "    file_path=file_path,\n",
    "    df_dict=df_dict,\n",
    "    decimal_places=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Contingency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import contingency_table\n",
    "\n",
    "# Example usage\n",
    "contingency_table(\n",
    "    df=df,\n",
    "    cols=[\n",
    "        \"age_group\",\n",
    "        \"workclass\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "    ],\n",
    "    sort_by=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting Specific Columns in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_toolkit import highlight_columns\n",
    "\n",
    "# Applying the highlight function\n",
    "highlighted_df = highlight_columns(\n",
    "    df=df.head(),\n",
    "    columns=[\"age\", \"education\"],\n",
    "    color=\"brown\",\n",
    ")\n",
    "\n",
    "highlighted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_eda_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
